version: '3.8'

services:
  megallm-proxy:
    build:
      context: .
      dockerfile: Dockerfile
    image: megallm-proxy:latest
    container_name: megallm-proxy
    ports:
      - "8000:8000"
    volumes:
      # 密钥文件（只读）
      - ./data/keys.txt:/app/data/keys.txt:ro
      # 日志目录（读写）
      - ./logs:/app/logs
      # 环境变量文件（只读，可选）
      - ./.env:/app/.env:ro
    environment:
      # 日志级别
      - LOG_LEVEL=INFO
      # 服务配置
      - HOST=0.0.0.0
      - PORT=8000
      # MegaLLM 配置（可选，会覆盖 .env）
      # - MEGALLM_BASE_URL=https://ai.megallm.io/v1
      # - MEGALLM_TIMEOUT=120.0
      # - MEGALLM_MAX_RETRIES=3
      # - MAX_KEY_RETRIES=3
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    # 资源限制（根据服务器配置调整）
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    # 网络配置
    networks:
      - megallm-network

networks:
  megallm-network:
    driver: bridge
